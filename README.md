# MLSDM Governed Cognitive Memory v1.0.0

Production-ready neurobiologically-grounded cognitive architecture with moral governance, phase-based memory, and cognitive rhythm. Universal wrapper for any LLM with hard biological constraints.

## Status: Production-Ready v1.0.0

**What Works:**
- âœ… **Universal LLM Wrapper** - wrap any LLM with cognitive governance
- âœ… Thread-safe concurrent processing (verified 1000+ RPS)
- âœ… Bounded memory (20k capacity, â‰¤1.4 GB RAM, zero-allocation after startup)
- âœ… Adaptive moral homeostasis (EMA + dynamic threshold, no RLHF)
- âœ… Circadian rhythm (8 wake + 3 sleep cycles with forced short responses)
- âœ… Phase-entangling retrieval (QILM v2) - fresh in wake, consolidated in sleep
- âœ… Multi-level synaptic memory (L1/L2/L3 with different Î»-decay)

**Verified:**
- Concurrency: 1000 parallel requests, zero lost updates
- Memory: Fixed 29.37 MB, no leaks
- Moral convergence: Tested with 200-step sequences

**Effectiveness Validation (Principal System Architect Level):**
- âœ… **89.5% resource efficiency** improvement with wake/sleep cycles
- âœ… **93.3% toxic content rejection** with moral filtering (vs 0% baseline)
- âœ… **5.5% coherence improvement** with phase-based memory organization
- âœ… **Stable under attack**: Bounded drift (0.33) during 70% toxic bombardment
- ðŸ“Š See [EFFECTIVENESS_VALIDATION_REPORT.md](EFFECTIVENESS_VALIDATION_REPORT.md) for full analysis

## Installation

```bash
pip install -r requirements.txt
python tests/integration/test_end_to_end.py
```

## Quick Start

### Universal LLM Wrapper (Recommended)

Wrap any LLM with cognitive governance:

```python
from src.core.llm_wrapper import LLMWrapper
import numpy as np

# Your LLM function (OpenAI, Anthropic, local model, etc.)
def my_llm(prompt: str, max_tokens: int) -> str:
    # Your LLM integration here
    return "LLM response"

# Your embedding function
def my_embedder(text: str) -> np.ndarray:
    # Your embedding model here (sentence-transformers, OpenAI, etc.)
    return np.random.randn(384).astype(np.float32)

# Create wrapper
wrapper = LLMWrapper(
    llm_generate_fn=my_llm,
    embedding_fn=my_embedder,
    dim=384,
    capacity=20_000,  # Hard memory limit
    wake_duration=8,
    sleep_duration=3,
    initial_moral_threshold=0.50
)

# Generate with governance
result = wrapper.generate(
    prompt="Hello, how are you?",
    moral_value=0.8  # Moral score (0.0-1.0)
)

print(result["response"])
print(f"Phase: {result['phase']}, Accepted: {result['accepted']}")
```

See `examples/llm_wrapper_example.py` for complete examples.

### Low-Level Cognitive Controller

For direct cognitive memory operations:

```python
from src.core.cognitive_controller import CognitiveController
import numpy as np

controller = CognitiveController(dim=384)
vector = np.random.randn(384).astype(np.float32)
vector = vector / np.linalg.norm(vector)

state = controller.process_event(vector, moral_value=0.8)
print(state)
```

## Architecture

**Components:**
- `MoralFilterV2`: Adaptive moral threshold (0.30-0.90) with EMA
- `QILM_v2`: Bounded quantum-inspired memory with phase entanglement
- `MultiLevelSynapticMemory`: 3-level decay (L1/L2/L3)
- `CognitiveRhythm`: Wake/sleep cycle (8/3 duration)
- `CognitiveController`: Thread-safe orchestrator

**Formulas:**
```
EMA: Î±Â·signal + (1-Î±)Â·EMA_prev
Threshold: clip(threshold + 0.05Â·sign(error), 0.30, 0.90)
Cosine: dot(A,B) / (||A||Â·||B||)
```

## Performance

- P50 latency: ~2ms (process_event)
- P95 latency: ~10ms (with retrieval)
- Throughput: 5,500 ops/sec (verified)
- Memory: 29.37 MB (fixed)

## Tests

```bash
# Basic integration tests
python tests/integration/test_end_to_end.py

# Effectiveness validation (Principal System Architect level)
python tests/validation/test_wake_sleep_effectiveness.py
python tests/validation/test_moral_filter_effectiveness.py

# Generate visualization charts
python scripts/generate_effectiveness_charts.py

# Moral convergence (quick test)
python -c "
from src.cognition.moral_filter_v2 import MoralFilterV2
m = MoralFilterV2(0.50)
for _ in range(200):
    m.evaluate(0.1)
    m.adapt(False)
print('Final:', m.threshold)
assert m.threshold == 0.30
print('PASS')
"
```

## Legacy API and Simulation

```bash
# Run simulation (legacy)
python -m src.main --steps 100 --plot

# Run API (legacy)
python -m src.main --api

# Run unit tests (legacy)
make test            # run unit + property tests
pytest -k property   # run property-based invariants (Hypothesis)
pytest -k state      # run state machine transition tests
```

## Testing & Verification Strategy (Principal System Architect Level)
This project incorporates advanced system reliability, mathematical correctness, AI safety, and performance validation methodologies expected at Principal / Staff engineering levels.

### Verification Pillars
1. Invariant Verification (Formal & Property-Based)
2. Resilience & Chaos Robustness
3. AI Governance & Safety Hardening
4. Performance & Saturation Profiling
5. Drift & Alignment Stability
6. Observability of Tail Failure Modes

### Methodologies Implemented / Planned
| Category | Method | Purpose | Tooling |
|----------|--------|---------|---------|
| Resilience | Chaos Engineering / Fault Injection | Validate graceful degradation under component failure (DB/network/pod kill) | chaos-toolkit, custom fault scripts |
| Resilience | Soak Testing (48â€“72h) | Detect memory leaks, latent resource exhaustion | Locust / custom harness + Prometheus export |
| Resilience | Load Shedding & Backpressure Testing | Ensure overload results in fast rejection, not collapse | Rate limit middleware + stress generators |
| Correctness | Property-Based Testing | Assert mathematical invariants across wide input space | Hypothesis |
| Correctness | State Machine Verification | Enforce legal cognitive rhythm transitions (Sleepâ†’Wakeâ†’Processing) | pytest state model + TLA+ spec alignment |
| AI Safety | Adversarial Red Teaming | Jailbreak & prompt-injection resistance for MoralFilter | Attack LLM harness + curated attack corpus |
| AI Safety | Cognitive Drift Testing | Ensure moral thresholds remain stable under toxic sequence bombardment | Drift probes + statistical monitoring |
| AI Safety | RAG Hallucination / Faithfulness Testing | Quantify grounding vs fabrication | ragas + retrieval audit logs |
| Performance | Saturation Testing | Identify RPS inflection where latency spikes | Locust/K6 + SLO dashboards |
| Performance | Tail Latency (P99/P99.9) Audits | Guarantee upper-bound latency SLOs | OpenTelemetry + Prometheus histograms |
| Formal | Formal Specification (TLA+) | Prove liveness/safety of memory lifecycle | TLC model checker |
| Formal | Algorithm Proof Fragments (Coq) | Prove correctness of address selection / neighbor threshold | Coq scripts |
| Governance | Ethical Override Traceability | Ensure explainable policy decisions | Structured event logging |
| Reliability | Drift & Anomaly Injection | Validate detection pipeline reaction | Synthetic anomaly injectors |

### Core Invariants (Examples)
- Moral filter threshold T always âˆˆ [0.1, 0.9].
- Episodic graph remains acyclic (no circular temporal references).
- State cannot jump directly from Sleep â†’ Processing without Wake.
- Retrieval under corruption degrades to stateless fallback but always returns a syntactically valid response envelope.

### Sample Property-Based Invariant (Hypothesis Sketch)
```python
from hypothesis import given, strategies as st
from src.moral import clamp_threshold

@given(t=st.floats(min_value=-10, max_value=10))
def test_moral_threshold_clamped(t):
    clamped = clamp_threshold(t)
    assert 0.1 <= clamped <= 0.9
```

### Chaos Scenarios (Initial Set)
1. Kill vector DB container mid high-RPS retrieval.
2. Introduce 3000ms network latency between memory and policy service.
3. Randomly corrupt 0.5% of episodic entries â†’ verify integrity alarms trigger & quarantine.
4. Simulated clock skew in circadian scheduler.

### Performance SLO Focus
- P95 composite memory retrieval < 120ms.
- P99 policy decision < 60ms.
- Error budget: â‰¤ 2% degraded cycles per 24h.

### AI Safety Metrics
- Drift Î”(moral_threshold) over toxic storm < 0.05 absolute.
- Hallucination rate (ragas) < 0.15.
- Successful jailbreak attempts < 0.5% of adversarial batch.

### Observability Hooks
- event_formal_violation, event_drift_alert, event_chaos_fault.
- Prometheus histograms: retrieval_latency_bucket, moral_filter_eval_ms.
- OpenTelemetry trace: MemoryRetrieve â†’ SemanticMerge â†’ PolicyCheck.

### Toolchain
- Hypothesis, pytest, chaos-toolkit, Locust/K6, ragas, TLA+, Coq, OpenTelemetry, Prometheus.

## Documentation

Complete documentation is available:

- ðŸ“– **[Documentation Index](DOCUMENTATION_INDEX.md)** - Complete documentation roadmap
- ðŸ“š **[Usage Guide](USAGE_GUIDE.md)** - Detailed usage examples and best practices
- ðŸ“– **[API Reference](API_REFERENCE.md)** - Complete API documentation
- ðŸš€ **[Deployment Guide](DEPLOYMENT_GUIDE.md)** - Production deployment patterns
- ðŸ¤ **[Contributing Guide](CONTRIBUTING.md)** - How to contribute to the project
- ðŸ—ï¸ **[Architecture Spec](ARCHITECTURE_SPEC.md)** - System architecture details
- âœ… **[Testing Strategy](TESTING_STRATEGY.md)** - Testing methodology
- ðŸ“Š **[Effectiveness Report](EFFECTIVENESS_VALIDATION_REPORT.md)** - Validation results
- ðŸ”’ **[Security Policy](SECURITY_POLICY.md)** - Security guidelines

**Quick Links by Role:**
- **Developers**: Start with [Usage Guide](USAGE_GUIDE.md) â†’ [API Reference](API_REFERENCE.md)
- **DevOps**: Start with [Deployment Guide](DEPLOYMENT_GUIDE.md) â†’ [SLO Spec](SLO_SPEC.md)
- **Contributors**: Start with [Contributing Guide](CONTRIBUTING.md) â†’ [Testing Strategy](TESTING_STRATEGY.md)

## Contributing

We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for:
- Development setup and workflow
- Coding standards and style guide
- Testing requirements (90%+ coverage)
- Pull request process
- Release procedures

**Quick Start for Contributors:**
```bash
# Fork and clone the repository
git clone https://github.com/YOUR_USERNAME/mlsdm-governed-cognitive-memory.git
cd mlsdm-governed-cognitive-memory

# Install dependencies
pip install -r requirements.txt

# Run tests
pytest tests/ src/tests/ -v --cov=src

# Run linting
ruff check src/ tests/
```

## License

MIT License - see LICENSE file

## Citation

```bibtex
@software{mlsdm2025,
  title={MLSDM Governed Cognitive Memory},
  author={neuron7x},
  year={2025},
  url={https://github.com/neuron7x/mlsdm-governed-cognitive-memory}
}
```

---

**Note:** This is an Alpha release. Production use requires additional hardening (monitoring, logging, error handling).

## Legacy Documentation

For information about advanced testing methodologies and verification strategies, see the sections below.