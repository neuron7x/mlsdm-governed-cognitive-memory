# MLSDM Agent/API Mode Environment Configuration
# ================================================
#
# Copy this file to .env.agent and customize for your API integration.
# Use with: make run-agent
#
# This mode is designed for:
# - LLM platform integration
# - External client APIs
# - Multi-agent systems
# - LangChain/LlamaIndex integrations

# ============================================================
# Runtime Mode
# ============================================================
MLSDM_RUNTIME_MODE=agent-api

# ============================================================
# Server Configuration
# ============================================================
HOST=0.0.0.0
PORT=8000
MLSDM_WORKERS=2
MLSDM_RELOAD=false
MLSDM_LOG_LEVEL=info

# ============================================================
# Security (configured for API access)
# ============================================================
# Required: Set API key for external clients
API_KEY=your-agent-api-key-change-me

# Rate limiting enabled to prevent abuse
DISABLE_RATE_LIMIT=0
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_WINDOW=60

# Secure mode enabled for production use
MLSDM_SECURE_MODE=1

# ============================================================
# Observability
# ============================================================
LOG_LEVEL=INFO
JSON_LOGGING=true
ENABLE_METRICS=true

# Tracing optional for agent mode
OTEL_SDK_DISABLED=true
OTEL_EXPORTER_TYPE=none

# ============================================================
# Engine Configuration
# ============================================================
# Configure your LLM backend
LLM_BACKEND=openai
OPENAI_API_KEY=sk-your-openai-key-here
# OPENAI_MODEL=gpt-3.5-turbo

# Use production config
CONFIG_PATH=config/production.yaml

# Embedding dimensions
EMBEDDING_DIM=384

# Enable full governance for agent mode
ENABLE_FSLGS=true

# ============================================================
# API Endpoints (for client integration)
# ============================================================
# POST /generate
#   Request: {"prompt": "...", "moral_value": 0.8}
#   Response: {"response": "...", "accepted": true, "phase": "wake"}
#
# POST /infer
#   Request: {"prompt": "...", "secure_mode": true, "aphasia_mode": true}
#   Response: {"response": "...", "accepted": true, "moral_metadata": {...}}
#
# GET /status
#   Response: {"status": "ok", "version": "1.2.0", "backend": "openai"}
#
# GET /health
#   Response: {"status": "healthy"}
